## Data Machine Copilot Guide
- **Orientation** Skim `docs/overview.md`, `docs/architecture.md`, and `CLAUDE.md`; `datamachine.php` boots after `datamachine_check_requirements()` validates PHP, Action Scheduler, and autoloaders.
- **Composer autoload** `composer.json` PSR-4 maps `DataMachine\Api|Core|Engine` to `inc/`; every `*Filters.php` listed under `autoload.files` auto-runs to register WordPress hooks—new services belong in that pattern.
- **Pipeline engine** Pipelines (templates) feed flows (configured instances) which create jobs (executions); `inc/Engine/Actions/DataMachineActions.php` drives `datamachine_run_flow_now` → `datamachine_execute_step` → `datamachine_schedule_next_step`.
- **Identifier helpers** Keep pipeline step IDs as UUIDs and derive flow step IDs via `datamachine_generate_flow_step_id`; split components with `datamachine_split_pipeline_step_id` / `_flow_step_id` instead of manual string ops.
- **Database layer** Always fetch repositories through `apply_filters('datamachine_db', [])`; implementations in `inc/Core/Database/**` manage the `wp_datamachine_*` tables and expect sanitized arguments.
- **Data packets vs engine data** Build AI-visible payloads with `datamachine_data_packet` while persisting URLs/media via `datamachine_engine_data(null, $job_id, [...])`; publish/update handlers must read via `apply_filters('datamachine_engine_data', [], $job_id)`.
- **Deduping contract** Fetch handlers should return `['processed_items' => [...]]` and invoke `do_action('datamachine_mark_item_processed', ...)`; reuse `datamachine_timeframe_limit` and `datamachine_keyword_search_match` helpers from `inc/Engine/Filters/Handlers.php`.
- **AI directive stack** Directive filters fire in priority order (PluginCore → GlobalSystemPrompt → PipelineSystem → ToolDefinitions → SiteContext); `AIStepConversationManager` maintains turn order and `AIStepToolParameters` builds flat tool payloads.
- **Tool enablement** Respect the three gates: site-wide toggle (`enabled_tools`), per-step modal selection, and runtime `datamachine_tool_configured` check; handler tools live beside their handlers, general tools under `inc/Core/Steps/AI/Tools`.
- **Handler registration** Add fetch/publish/update handlers, auth providers, and tools via their filter arrays (`datamachine_handlers`, `datamachine_auth_providers`, `ai_tools`); keep the label/description/`requires_auth` shape consistent.
- **WordPress publisher modules** `inc/Core/Steps/Publish/Handlers/WordPress` delegates to `FeaturedImageHandler`, `TaxonomyHandler`, `SourceUrlHandler`; system defaults override per-step config, so read global settings before mutating handler options.
- **Update workflows** Update steps no-op without `source_url` in engine data—ensure upstream fetch/tool steps populate it (WordPress Local, Local Search, Post Reader).
- **REST surface** Endpoint classes in `inc/Api/*.php` self-register during `run_data_machine()`; enforce `manage_options` capability and reuse the `{success, data, message}` envelope when extending routes.
- **Cache management** Clear caches through `datamachine_clear_*` actions in `inc/Engine/Actions/Cache.php`; never manipulate WordPress transients directly.
- **Logging** Emit diagnostics with `do_action('datamachine_log', $level, $message, $context)`; Monolog setup under `inc/Engine/Filters/Logger.php` handles rotation and formatting.
- **AutoSave flow** Pipeline edits funnel through `do_action('datamachine_auto_save', $pipeline_id)` which syncs flows, steps, and caches—avoid piecemeal persistence.
- **React admin** Edit sources under `inc/Core/Admin/Pages/Pipelines/assets/react`; `npm run start` (wp-scripts) provides HMR, `npm run build` feeds the production bundle consumed by PHP enqueue scripts.
- **Frontend data access** React hooks (`usePipelines`, `useFlows`, `useStepTypes`, etc.) call a shared `apiFetch` wrapper (`assets/react/utils/api.js`) that already injects nonces and parses the REST envelope—reuse it for new endpoints.
- **Tool-first AI** All publish handlers expose `handle_tool_call()`; use `AIStepToolParameters::buildForHandlerTool()` to merge data packet content with handler config and engine data.
- **Action Scheduler dependency** Ensure `vendor/woocommerce/action-scheduler` is loaded before scheduling; long-running jobs should confirm queue availability via Action Scheduler helper methods.
- **Caching + status UI** Cache keys follow the `datamachine_` prefix; `datamachine_clear_pipelines_list_cache` and friends power the Pipelines React status badges, so fire them after structural changes.
- **Composer tasks** `composer install` bootstraps required deps (`chubes4/ai-http-client`, Action Scheduler, Monolog); `composer test`, `test:unit`, and `test:integration` run phpunit with Yoast polyfills.
- **Build workflow** `./build.sh` expects `.buildignore`, rsync, composer, npm; it installs prod deps, runs `npm run build`, zips to `dist/datamachine.zip`, then restores dev deps automatically.
- **React deploy** After `npm run build`, enqueue scripts read from the generated asset manifest—never commit `dist/` output, rely on the build script for release artifacts.
- **Logging + errors** REST controllers wrap responses in try/catch and populate the `message` field; mirror that pattern and route fatal issues through `do_action('datamachine_log', 'error', ...)` for consistency.
- **Cross-plugin contracts** Sibling packages (`datamachine-*` repos) consume these hooks; document breaking changes in `MIGRATION-PLAN.md` and bump shared filters cautiously.
- **Migration context** Prefix migration complete (`datamachine_` for hooks, `wp_datamachine_*` tables, `datamachine-` CSS classes); new code should never introduce legacy `dm_` identifiers.
